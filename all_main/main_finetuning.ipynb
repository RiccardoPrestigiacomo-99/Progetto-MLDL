{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoPrestigiacomo-99/Progetto-MLDL/blob/main/all_main/main_finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j40FSXGxD2VD"
      },
      "source": [
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uudv9Cj8E8OI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "475c6ef3-99da-4a03-f744-3b76c15c9b23"
      },
      "source": [
        "\"\"\"!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"!pip3 install 'torch==1.3.1'\\n!pip3 install 'torchvision==0.5.0'\\n!pip3 install 'Pillow-SIMD'\\n!pip3 install 'tqdm'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dC-rYdjD-E3"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6tCA_s2rru"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Lf-WK3hEJCM"
      },
      "source": [
        "**Retrieving dataset CIFAR1000**<br>\n",
        "The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. There are 500 training images and 100 testing images per class.\n",
        "The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "Here is an example of classes in the CIFAR-100:<br>\n",
        "**Superclass**\t\n",
        "- aquatic mammals\t\n",
        "\n",
        "**Classes**\n",
        "- beaver, dolphin, otter, seal, whale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n1do9ln3OVE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65caff23-88f6-466c-830d-1fca6ed40e8c"
      },
      "source": [
        "DATA_DIR = 'DATA' # here the dataset will be downloaded\n",
        "\n",
        "# Clone github repository with dataset handler\n",
        "!rm -r Cifar100/\n",
        "!rm -r $DATA_DIR\n",
        "!mkdir \"DATA\"\n",
        "if not os.path.isdir('./Cifar100'):\n",
        "  !git clone https://github.com/RiccardoPrestigiacomo-99/Progetto-MLDL.git\n",
        "  !mv 'Progetto-MLDL' 'Cifar100'\n",
        "  !rm -r Cifar100/Theoretical-Sources\n",
        "  !rm -rf Cifar100/ProjectMLDL.ipynb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Progetto-MLDL'...\n",
            "remote: Enumerating objects: 46, done.\u001b[K\n",
            "remote: Counting objects:   2% (1/46)\u001b[K\rremote: Counting objects:   4% (2/46)\u001b[K\rremote: Counting objects:   6% (3/46)\u001b[K\rremote: Counting objects:   8% (4/46)\u001b[K\rremote: Counting objects:  10% (5/46)\u001b[K\rremote: Counting objects:  13% (6/46)\u001b[K\rremote: Counting objects:  15% (7/46)\u001b[K\rremote: Counting objects:  17% (8/46)\u001b[K\rremote: Counting objects:  19% (9/46)\u001b[K\rremote: Counting objects:  21% (10/46)\u001b[K\rremote: Counting objects:  23% (11/46)\u001b[K\rremote: Counting objects:  26% (12/46)\u001b[K\rremote: Counting objects:  28% (13/46)\u001b[K\rremote: Counting objects:  30% (14/46)\u001b[K\rremote: Counting objects:  32% (15/46)\u001b[K\rremote: Counting objects:  34% (16/46)\u001b[K\rremote: Counting objects:  36% (17/46)\u001b[K\rremote: Counting objects:  39% (18/46)\u001b[K\rremote: Counting objects:  41% (19/46)\u001b[K\rremote: Counting objects:  43% (20/46)\u001b[K\rremote: Counting objects:  45% (21/46)\u001b[K\rremote: Counting objects:  47% (22/46)\u001b[K\rremote: Counting objects:  50% (23/46)\u001b[K\rremote: Counting objects:  52% (24/46)\u001b[K\rremote: Counting objects:  54% (25/46)\u001b[K\rremote: Counting objects:  56% (26/46)\u001b[K\rremote: Counting objects:  58% (27/46)\u001b[K\rremote: Counting objects:  60% (28/46)\u001b[K\rremote: Counting objects:  63% (29/46)\u001b[K\rremote: Counting objects:  65% (30/46)\u001b[K\rremote: Counting objects:  67% (31/46)\u001b[K\rremote: Counting objects:  69% (32/46)\u001b[K\rremote: Counting objects:  71% (33/46)\u001b[K\rremote: Counting objects:  73% (34/46)\u001b[K\rremote: Counting objects:  76% (35/46)\u001b[K\rremote: Counting objects:  78% (36/46)\u001b[K\rremote: Counting objects:  80% (37/46)\u001b[K\rremote: Counting objects:  82% (38/46)\u001b[K\rremote: Counting objects:  84% (39/46)\u001b[K\rremote: Counting objects:  86% (40/46)\u001b[K\rremote: Counting objects:  89% (41/46)\u001b[K\rremote: Counting objects:  91% (42/46)\u001b[K\rremote: Counting objects:  93% (43/46)\u001b[K\rremote: Counting objects:  95% (44/46)\u001b[K\rremote: Counting objects:  97% (45/46)\u001b[K\rremote: Counting objects: 100% (46/46)\u001b[K\rremote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 46 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (46/46), done.\n",
            "rm: cannot remove 'Cifar100/Theoretical-Sources': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysghtAWOPYZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca3013f3-47ad-4d1f-d2f5-a7269d935602"
      },
      "source": [
        "# Download dataset from the official source and save it into DATA/cifar-100-pyhton\n",
        "\n",
        "if not os.path.isdir('./{}'.format(\"$DATA_DIR/cifar-100-python\")):\n",
        "    !wget https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
        "    !tar -xf 'cifar-100-python.tar.gz'  \n",
        "    !mkdir $DATA_DIR\n",
        "    !mv 'cifar-100-python' \"$DATA_DIR/cifar-100-python\"\n",
        "    !rm -rf 'cifar-100-python.tar.gz'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-05 19:36:42--  https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 169001437 (161M) [application/x-gzip]\n",
            "Saving to: ‘cifar-100-python.tar.gz’\n",
            "\n",
            "cifar-100-python.ta 100%[===================>] 161.17M  71.1MB/s    in 2.3s    \n",
            "\n",
            "2021-06-05 19:36:44 (71.1 MB/s) - ‘cifar-100-python.tar.gz’ saved [169001437/169001437]\n",
            "\n",
            "mkdir: cannot create directory ‘DATA’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XOn3bHMEBzX"
      },
      "source": [
        "**Set arguments** - \n",
        "src: iCaRL section 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-pqSNg4_Ris",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda6debc-c098-4cc5-dcd2-a199c1f44529"
      },
      "source": [
        "from Cifar100 import utils\n",
        "dictHyperparams = utils.getHyperparams()\n",
        "print(dictHyperparams)\n",
        "\n",
        "DEVICE = dictHyperparams[\"DEVICE\"] # 'cuda' or 'cpu'\n",
        "NUM_CLASSES = dictHyperparams[\"NUM_CLASSES\"] \n",
        "\n",
        "BATCH_SIZE = dictHyperparams[\"BATCH_SIZE\"]     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "\n",
        "LR = 0.1         # The initial Learning Rate\n",
        "MOMENTUM = dictHyperparams[\"MOMENTUM\"]       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = dictHyperparams[\"WEIGHT_DECAY\"] # Regularization, you can keep this at the default\n",
        "\n",
        "# NUM_EPOCHS = dictHyperparams[\"NUM_EPOCHS\"]     # Total number of training epochs (iterations over dataset)\n",
        "NUM_EPOCHS  = 30\n",
        "GAMMA = dictHyperparams[\"GAMMA\"]         # Multiplicative factor for learning rate step-down\n",
        "\n",
        "LOG_FREQUENCY = dictHyperparams[\"LOG_FREQUENCY\"]\n",
        "MILESTONES = dictHyperparams[\"MILESTONES\"]\n",
        "RANDOM_SEED = dictHyperparams[\"SEED\"]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'LR': 2, 'MOMENTUM': 0.9, 'WEIGHT_DECAY': 1e-05, 'NUM_EPOCHS': 70, 'MILESTONES': [49, 63], 'BATCH_SIZE': 128, 'DEVICE': 'cuda', 'GAMMA': 0.2, 'SEED': 66, 'LOG_FREQUENCY': 10, 'NUM_CLASSES': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oJ5m4V-ERDh"
      },
      "source": [
        "**Define data preprocessing**<br>\n",
        "This transformations are applied to each images when they're loaded into the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_jHycn_1kk"
      },
      "source": [
        "train_transform, eval_transform = utils.getTransformations()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7EVuDrcJj2N"
      },
      "source": [
        "**Prepare dataset**<br>\n",
        "Loading of the train and test split as it comes with CIFAR100. <br>\n",
        "The trainset consists in 50k images, while the test set len is 10k images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJKwvGljJj2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5871a3d-1dc9-431e-9326-955eeaf52ac9"
      },
      "source": [
        "from Cifar100.Dataset.cifar100 import CIFAR100\n",
        "\n",
        "# Import dataset\n",
        "train_dataset = CIFAR100(DATA_DIR, split='train', transform=train_transform)\n",
        "test_dataset = CIFAR100(DATA_DIR, split='test', transform=eval_transform)\n",
        "\n",
        "# check if datasets have been correctly loaded\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckn3H69iJj2X"
      },
      "source": [
        "from Cifar100.reverse_index import ReverseIndex\n",
        "\n",
        "def build_test_splits(dataset, reverse_index):\n",
        "    splits = dict()\n",
        "    groups = list(reverse_index.getGroups())\n",
        "    for g in groups:\n",
        "        labels_of_groups = reverse_index.getLabelsOfGroup(g)\n",
        "        indices = list(dataset.df[dataset.df['labels'].isin(labels_of_groups)].index)\n",
        "        splits[g] = indices\n",
        "    return splits"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYLmmQn7JOLc"
      },
      "source": [
        "**Build dataset splits and reverse index**<br>\n",
        "Here the train dataset is split into train and validation set, following the proportion XX/YY.<br>\n",
        "Furthermore train, test and validation sets are splitted into 10 groups containing 10 classes each (the split is coherent among the different sets).<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpcJvhxhJOLc"
      },
      "source": [
        "# performing the train/val split\n",
        "train_splits = train_dataset.split_in_train_val_groups(ratio=0.99, seed=RANDOM_SEED)\n",
        "outputs_labels_mapping = ReverseIndex(train_dataset, train_splits)\n",
        "\n",
        "# performing the test split (coherent with train/val)\n",
        "test_splits = build_test_splits(test_dataset, outputs_labels_mapping)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7fov9YAFTlj"
      },
      "source": [
        "**Prepare dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5MSItI0QVpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2941461a-5eab-4557-9bce-d1c5938de3ec"
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "train_subsets = []\n",
        "val_subsets = []\n",
        "test_subsets = []\n",
        "\n",
        "for v in train_splits.values():\n",
        "    train_subs = Subset(train_dataset, v['train'])\n",
        "    val_subs = Subset(train_dataset, v['val'])\n",
        "    train_subsets.append(train_subs)\n",
        "    val_subsets.append(val_subs)\n",
        "\n",
        "for i in range(0,10):\n",
        "    v=test_splits[i]\n",
        "    test_subs = Subset(test_dataset, v)\n",
        "    test_subsets.append(test_subs)\n",
        "\n",
        "# [ DEBUG ]\n",
        "# test to check classes in different dataset\n",
        "# (coherent split)\n",
        "# RESULT: OK\n",
        "\"\"\"dict_train={}\n",
        "for img_train in train_subsets[0]:\n",
        "  if img_train[1] not in dict_train:\n",
        "    dict_train[img_train[1]]=1\n",
        "  else:\n",
        "    dict_train[img_train[1]]+=1\n",
        "dict_val={}\n",
        "for img_val in val_subsets[0]:\n",
        "  if img_val[1] not in dict_val:\n",
        "    dict_val[img_val[1]]=1\n",
        "  else:\n",
        "    dict_val[img_val[1]]+=1\n",
        "dict_test={}\n",
        "for img_test in test_subsets[0]:\n",
        "  if img_test[1] not in dict_test:\n",
        "    dict_test[img_test[1]]=1\n",
        "  else:\n",
        "    dict_test[img_test[1]]+=1\n",
        "\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\n",
        "print(sorted(dict_test.keys()))\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dict_train={}\\nfor img_train in train_subsets[0]:\\n  if img_train[1] not in dict_train:\\n    dict_train[img_train[1]]=1\\n  else:\\n    dict_train[img_train[1]]+=1\\ndict_val={}\\nfor img_val in val_subsets[0]:\\n  if img_val[1] not in dict_val:\\n    dict_val[img_val[1]]=1\\n  else:\\n    dict_val[img_val[1]]+=1\\ndict_test={}\\nfor img_test in test_subsets[0]:\\n  if img_test[1] not in dict_test:\\n    dict_test[img_test[1]]=1\\n  else:\\n    dict_test[img_test[1]]+=1\\n\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))\\nprint(sorted(dict_test.keys()))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d19CnhIUg0q"
      },
      "source": [
        "**Utility functions to use our customized resnet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ff9pwV10b0v"
      },
      "source": [
        "from Cifar100.resnet import CifarResNet\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getResNet32():\n",
        "    net = CifarResNet()\n",
        "    # net.fc = nn.Linear(net.fc.in_features, output_size) # embedded in the class\n",
        "\n",
        "    criterion = utils.getLossCriterion()\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return net, criterion, optimizer, scheduler\n",
        "\n",
        "def addOutputs(net, num):\n",
        "    net.addOutputNodes(num)\n",
        "\n",
        "def getNet():\n",
        "    return getResNet32()\n",
        "\n",
        "def getSchedulerOptimizer(net):\n",
        "    parameters_to_optimize = net.parameters()\n",
        "    optimizer, scheduler = utils.getOptimizerScheduler(LR, MOMENTUM, WEIGHT_DECAY, MILESTONES, GAMMA, parameters_to_optimize)\n",
        "    return optimizer, scheduler"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glyt2p3XTEqt"
      },
      "source": [
        "**Basic train, test and validation functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzG6w15UudAP"
      },
      "source": [
        "def train(net, train_dataloader, criterion, optimizer, scheduler, num_classes, num_epochs=NUM_EPOCHS):     \n",
        "    # By default, everything is loaded to cpu\n",
        "    net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "\n",
        "    cudnn.benchmark # Calling this optimizes runtime\n",
        "    \n",
        "    current_step = 0\n",
        "    # Start iterating over the epochs\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        net.train()\n",
        "        print('Starting epoch {}/{}, LR = {}'.format(epoch+1, num_epochs, scheduler.get_lr()))\n",
        "\n",
        "        running_corrects = 0\n",
        "        running_loss = 0.0\n",
        "        for _, images, labels in train_dataloader:\n",
        "            # Bring data over the device of choice\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "            labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            outputsT = net(images)\n",
        "            outputs = net.predict(outputsT)\n",
        "\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            \n",
        "            # Get predictions\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            # preds = getLabels(outputs_labels_mapping, preds)\n",
        "            # print(preds)\n",
        "            \n",
        "            # Update Corrects & Loss\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "            # Log loss\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "                print('Train step - Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "            # Compute gradients for each layer and update weights\n",
        "            loss.backward()  # backward pass: computes gradients\n",
        "            optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "            current_step += 1\n",
        "        \n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate Accuracy & Loss\n",
        "        epoch_loss = running_loss / float(len(train_dataloader.dataset))\n",
        "        epoch_acc = running_corrects / float(len(train_dataloader.dataset))\n",
        "        \n",
        "        print('Train epoch - Accuracy: {} Loss: {} Corrects: {}'.format(epoch_acc, epoch_loss, running_corrects))\n",
        "    print('Training finished in {} seconds'.format(time.time() - start_time))\n",
        "\n",
        "def validate(net, val_dataloader, criterion, num_classes):\n",
        "    net.eval()\n",
        "\n",
        "    utils.getLossCriterion()\n",
        "\n",
        "    # confusion matrix\n",
        "    all_preds_cm = []\n",
        "    all_labels_cm = []\n",
        "\n",
        "    running_corrects = 0\n",
        "    running_loss = 0.0\n",
        "    for _, images, labels in val_dataloader:\n",
        "        # Bring data over the device of choice\n",
        "        images = images.to(DEVICE)\n",
        "        labels = labels.to(DEVICE)\n",
        "        #labels = outputs_labels_mapping.getNodes(labels)\n",
        "        labels_enc = utils._one_hot_encode(labels, num_classes, outputs_labels_mapping)\n",
        "        labels = outputs_labels_mapping.getNodes(labels)\n",
        "\n",
        "        # Forward pass to the network\n",
        "        outputsT = net(images)\n",
        "        outputs = net.predict(outputsT)\n",
        "        \n",
        "        # Update Corrects & Loss\n",
        "        if criterion is not None:\n",
        "            loss = utils.computeLoss(criterion, outputs, labels_enc)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        # preds = getLabels(outputs_labels_mapping, preds)\n",
        "        running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "        all_preds_cm.extend(preds.tolist())\n",
        "        all_labels_cm.extend(labels.data.tolist())\n",
        "\n",
        "    # Calculate Accuracy & Loss\n",
        "    loss = running_loss / float(len(val_dataloader.dataset))\n",
        "    acc = running_corrects / float(len(val_dataloader.dataset))\n",
        "\n",
        "    return acc, loss, all_preds_cm, all_labels_cm\n",
        "\n",
        "def test(net, test_dataloader, num_classes):\n",
        "    acc, _, all_preds_cm, all_labels_cm = validate(net, test_dataloader, None, num_classes)\n",
        "    return acc, np.array(all_preds_cm), np.array(all_labels_cm)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiWapdlNNsA0"
      },
      "source": [
        "**Joint Training**<br>\n",
        "In this section joint training is perfomed.<br>\n",
        "The train of the network is split into 10 stages, one for each subset classes.\n",
        "At each step, the network is trained on the images corresponding to the current 10 classes and all the data already seen in the previous steps.\n",
        "The joint training score, evaluated in terms of accuracy on the test set, gives us an UB for the next methodologies examined in this project (iCaRL, LWF).<br>\n",
        "Operatively, what happens is a very slow training and, furthermore, we break the assumption of not needing the previous batches of data at each step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4InuBhsENpV9"
      },
      "source": [
        "# ####\n",
        "# ## Joint training\n",
        "# ####\n",
        "# # Joins 2+ subsets into a new Subset (joint training)\n",
        "# def joinSubsets(dataset, subsets):\n",
        "#     indices = []\n",
        "#     for s in subsets:\n",
        "#         indices += s.indices\n",
        "#     return Subset(dataset, indices)\n",
        "\n",
        "# def jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets):\n",
        "#     net, criterion, optimizer, scheduler = getNet()\n",
        "\n",
        "#     train_set = None\n",
        "#     test_set = None\n",
        "#     first_pass = True\n",
        "\n",
        "#     current_train_num = 0\n",
        "#     total_trains = len(train_subsets)\n",
        "#     joint_start = time.time()\n",
        "\n",
        "#     print('\\n\\nJoint-training start\\n\\n')\n",
        "#     all_accuracies=[]\n",
        "#     for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "#         phase_start = time.time()\n",
        "#         print('\\n\\nJoint phase {}/{}\\n\\n'.format(current_train_num+1, total_trains))\n",
        "#         current_train_num += 1\n",
        "\n",
        "#         #num_classes_per_group = 10\n",
        "#         num_classes_seen = current_train_num*10\n",
        "\n",
        "#         # Builds growing train and test set. The new sets include data from previous class groups and current class group\n",
        "#         if train_set is None:\n",
        "#             train_set = train_subset\n",
        "#         else:\n",
        "#             train_set = joinSubsets(train_dataset, [train_set, train_subset])\n",
        "#         if test_set is None:\n",
        "#             test_set = test_subset\n",
        "#         else:\n",
        "#             test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "\n",
        "#         if first_pass:\n",
        "#             first_pass = False\n",
        "#         else:\n",
        "#             addOutputs(net, 10)\n",
        "\n",
        "#         # Trains model on previous and current class groups\n",
        "#         optimizer, scheduler = getSchedulerOptimizer(net)\n",
        "#         train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "#         train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "#         # Validate model on current class group\n",
        "#         val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "#         v_acc, v_loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "#         print('\\nValidation accuracy: {} - Validation loss: {}\\n'.format(v_acc, v_loss))\n",
        "\n",
        "#         # Test the model on previous and current class groups\n",
        "#         test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, drop_last=False)\n",
        "#         acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "#         all_accuracies.append(acc_all)\n",
        "#         print('\\nTest accuracy: {}\\n'.format(acc_all))\n",
        "\n",
        "#         print('\\n\\nPhase completed in {} seconds\\n\\n'.format(time.time() - phase_start))\n",
        "    \n",
        "#     print('\\n\\n Joint-training finished in {} seconds'.format(time.time() - joint_start))\n",
        "#     return net, all_accuracies, all_preds_cm, all_labels_cm"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOiPlN8ON4Gn"
      },
      "source": [
        "**Test joint training**<br>\n",
        "What we expect is a test accuracy higher of what we'll be able to achieve using iCaRL, LWF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VDecUBiHl4G"
      },
      "source": [
        "# # Test Joint training\n",
        "\n",
        "# net, all_accuracies, all_preds_cm, all_labels_cm = jointTraining(getNet, addOutputs, train_subsets, val_subsets, test_subsets)\n",
        "\n",
        "# # output Joint training\n",
        "# method = \"jointtraining\"\n",
        "# print(\"metrics jointtraining for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "# data_plot_line=[]\n",
        "# for id in range(0,10):\n",
        "#     data_plot_line.append(((id+1)*10,all_accuracies[id]))\n",
        "\n",
        "# #plt.figure(figsize=(20,7))\n",
        "# #accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "# #ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "# #plt.title(\"Single Group Sequential Accuracy\")\n",
        "# #plt.show()\n",
        "\n",
        "# # plot accuracy trend\n",
        "# utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# # confusion matrix\n",
        "# confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "# utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# # write down json\n",
        "# utils.writeMetrics(method, RANDOM_SEED, all_accuracies, confusionMatrixData)\n",
        "\n",
        "# # [DEBUG]\n",
        "# #net, criterion, optimizer, scheduler = getResNet32()\n",
        "# #train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "# #train(net, train_dataloader, criterion, optimizer, scheduler)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pts78KY42gXj"
      },
      "source": [
        "**Fine tuning (catastrophic forgetting)**<br>\n",
        "In this section of the homework the aim is to demonstrate how, without ad-hoc methodologies, our CNN is unable to learn without dramatically forgetting what it has already been learnt.<br>\n",
        "Operatively, what we do is to perform a training again divided into (ten) steps but without exploiting previous data as before (joint training).\n",
        "What we should observe is a dramatic drop in the perfomances of the network.*italicized text*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGqCsW-whNpV"
      },
      "source": [
        "def joinSubsets(dataset, subsets):\n",
        "    indices = []\n",
        "    for s in subsets:\n",
        "        indices += s.indices\n",
        "    return Subset(dataset, indices)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrA3WhUzuK67"
      },
      "source": [
        "### Fine tuning\n",
        "def sequentialLearning(train_subsets, val_subsets, test_subsets):\n",
        "    net, criterion, optimizer, scheduler = getResNet32()\n",
        "    test_set = None\n",
        "    groups_accuracies=[]\n",
        "    all_accuracies=[]\n",
        "    group_id=1\n",
        "\n",
        "\n",
        "    for train_subset, val_subset, test_subset in zip(train_subsets, val_subsets, test_subsets):\n",
        "      \n",
        "      if test_set is None:\n",
        "        test_set = test_subset\n",
        "      else:\n",
        "        test_set = joinSubsets(test_dataset, [test_set, test_subset])\n",
        "        addOutputs(net,10)\n",
        "      \n",
        "      num_classes_per_group = 10\n",
        "      num_classes_seen = group_id*10\n",
        "\n",
        "      print(\"GROUP: \",group_id)\n",
        "      # Train on current group\n",
        "      optimizer, scheduler = getSchedulerOptimizer(net) # reset learning rate and step_size\n",
        "      train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      train(net, train_loader, criterion, optimizer, scheduler, num_classes_seen)\n",
        "\n",
        "      # Validate on current group\n",
        "      val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc, loss, _, _ = validate(net, val_loader, criterion, num_classes_seen)\n",
        "      print(\"EVALUATION: \",acc, loss)\n",
        "\n",
        "      # Test on current group\n",
        "      test_group_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_group, _, _ = test(net, test_group_loader, num_classes_seen)\n",
        "      groups_accuracies.append(acc_group)\n",
        "\n",
        "      test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "      acc_all, all_preds_cm, all_labels_cm = test(net, test_loader, num_classes_seen)\n",
        "      all_accuracies.append(acc_all)\n",
        "      \n",
        "      print(\"TEST GROUP: \",acc_group)\n",
        "      print(\"TEST ALL: \",acc_all)\n",
        "      group_id+=1\n",
        "\n",
        "    #confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "\n",
        "    return net, groups_accuracies, all_accuracies, all_preds_cm, all_labels_cm\n",
        "\n",
        "def printAccuracyDifference(net, old_accuracies):\n",
        "    dif_accuracies=[]\n",
        "    id_group=0\n",
        "    for test_subset in test_subsets:\n",
        "        test_loader = DataLoader(test_subset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "        acc = test(net, test_loader)\n",
        "        dif_accuracies.append((id_group+1,old_accuracies[id_group],acc))\n",
        "        id_group+=1\n",
        "    return dif_accuracies"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrMQy2TuUAb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3af87e-bc2a-4fa6-a1c3-b8f03786dd3e"
      },
      "source": [
        "# train\n",
        "net, old_accuracies, new_accuracies, all_preds_cm, all_labels_cm = sequentialLearning(train_subsets, val_subsets, test_subsets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GROUP:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Starting epoch 1/30, LR = [0.1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:417: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train step - Step 0, Loss 0.8373395800590515\n",
            "Train step - Step 10, Loss 0.3063872456550598\n",
            "Train step - Step 20, Loss 0.2945563495159149\n",
            "Train step - Step 30, Loss 0.2748163044452667\n",
            "Train epoch - Accuracy: 0.27494949494949494 Loss: 0.34889252218935224 Corrects: 1361\n",
            "Starting epoch 2/30, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.25722092390060425\n",
            "Train step - Step 50, Loss 0.26852133870124817\n",
            "Train step - Step 60, Loss 0.23050236701965332\n",
            "Train step - Step 70, Loss 0.22518940269947052\n",
            "Train epoch - Accuracy: 0.43212121212121213 Loss: 0.24578728408524483 Corrects: 2139\n",
            "Starting epoch 3/30, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.21665449440479279\n",
            "Train step - Step 90, Loss 0.2235567569732666\n",
            "Train step - Step 100, Loss 0.23998765647411346\n",
            "Train step - Step 110, Loss 0.2249419242143631\n",
            "Train epoch - Accuracy: 0.5022222222222222 Loss: 0.22320115073762758 Corrects: 2486\n",
            "Starting epoch 4/30, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.21729998290538788\n",
            "Train step - Step 130, Loss 0.2079559862613678\n",
            "Train step - Step 140, Loss 0.22160108387470245\n",
            "Train step - Step 150, Loss 0.20273907482624054\n",
            "Train epoch - Accuracy: 0.5371717171717172 Loss: 0.2109078328657632 Corrects: 2659\n",
            "Starting epoch 5/30, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.19456587731838226\n",
            "Train step - Step 170, Loss 0.1927860528230667\n",
            "Train step - Step 180, Loss 0.21424832940101624\n",
            "Train step - Step 190, Loss 0.20998826622962952\n",
            "Train epoch - Accuracy: 0.5507070707070707 Loss: 0.2039353071860593 Corrects: 2726\n",
            "Starting epoch 6/30, LR = [0.1]\n",
            "Train step - Step 200, Loss 0.20363135635852814\n",
            "Train step - Step 210, Loss 0.21431337296962738\n",
            "Train step - Step 220, Loss 0.2035764753818512\n",
            "Train step - Step 230, Loss 0.22410674393177032\n",
            "Train epoch - Accuracy: 0.5779797979797979 Loss: 0.19720029803839598 Corrects: 2861\n",
            "Starting epoch 7/30, LR = [0.1]\n",
            "Train step - Step 240, Loss 0.20401711761951447\n",
            "Train step - Step 250, Loss 0.21535229682922363\n",
            "Train step - Step 260, Loss 0.194223091006279\n",
            "Train step - Step 270, Loss 0.17466722428798676\n",
            "Train epoch - Accuracy: 0.576969696969697 Loss: 0.19355226075408435 Corrects: 2856\n",
            "Starting epoch 8/30, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.15853025019168854\n",
            "Train step - Step 290, Loss 0.191620871424675\n",
            "Train step - Step 300, Loss 0.18268291652202606\n",
            "Train step - Step 310, Loss 0.17693625390529633\n",
            "Train epoch - Accuracy: 0.6137373737373737 Loss: 0.1821664721134937 Corrects: 3038\n",
            "Starting epoch 9/30, LR = [0.1]\n",
            "Train step - Step 320, Loss 0.17704637348651886\n",
            "Train step - Step 330, Loss 0.15841083228588104\n",
            "Train step - Step 340, Loss 0.17944207787513733\n",
            "Train step - Step 350, Loss 0.17088106274604797\n",
            "Train epoch - Accuracy: 0.6218181818181818 Loss: 0.17535838333043186 Corrects: 3078\n",
            "Starting epoch 10/30, LR = [0.1]\n",
            "Train step - Step 360, Loss 0.19750705361366272\n",
            "Train step - Step 370, Loss 0.15540066361427307\n",
            "Train step - Step 380, Loss 0.1777055710554123\n",
            "Train epoch - Accuracy: 0.6450505050505051 Loss: 0.17077528568831357 Corrects: 3193\n",
            "Starting epoch 11/30, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.14935849606990814\n",
            "Train step - Step 400, Loss 0.1939910501241684\n",
            "Train step - Step 410, Loss 0.17566047608852386\n",
            "Train step - Step 420, Loss 0.16305379569530487\n",
            "Train epoch - Accuracy: 0.6581818181818182 Loss: 0.16363882910121572 Corrects: 3258\n",
            "Starting epoch 12/30, LR = [0.1]\n",
            "Train step - Step 430, Loss 0.17139273881912231\n",
            "Train step - Step 440, Loss 0.160532146692276\n",
            "Train step - Step 450, Loss 0.1712966412305832\n",
            "Train step - Step 460, Loss 0.17604906857013702\n",
            "Train epoch - Accuracy: 0.6690909090909091 Loss: 0.15747643962050928 Corrects: 3312\n",
            "Starting epoch 13/30, LR = [0.1]\n",
            "Train step - Step 470, Loss 0.13600918650627136\n",
            "Train step - Step 480, Loss 0.1443788856267929\n",
            "Train step - Step 490, Loss 0.13080184161663055\n",
            "Train step - Step 500, Loss 0.12317085266113281\n",
            "Train epoch - Accuracy: 0.697979797979798 Loss: 0.14933449759627834 Corrects: 3455\n",
            "Starting epoch 14/30, LR = [0.1]\n",
            "Train step - Step 510, Loss 0.12013473361730576\n",
            "Train step - Step 520, Loss 0.13452056050300598\n",
            "Train step - Step 530, Loss 0.16684630513191223\n",
            "Train step - Step 540, Loss 0.15937519073486328\n",
            "Train epoch - Accuracy: 0.6977777777777778 Loss: 0.1476636312284855 Corrects: 3454\n",
            "Starting epoch 15/30, LR = [0.1]\n",
            "Train step - Step 550, Loss 0.12408941984176636\n",
            "Train step - Step 560, Loss 0.15403063595294952\n",
            "Train step - Step 570, Loss 0.14006535708904266\n",
            "Train step - Step 580, Loss 0.137859046459198\n",
            "Train epoch - Accuracy: 0.7086868686868687 Loss: 0.1427835653225581 Corrects: 3508\n",
            "Starting epoch 16/30, LR = [0.1]\n",
            "Train step - Step 590, Loss 0.1414889693260193\n",
            "Train step - Step 600, Loss 0.13275617361068726\n",
            "Train step - Step 610, Loss 0.13946278393268585\n",
            "Train step - Step 620, Loss 0.1278153955936432\n",
            "Train epoch - Accuracy: 0.7147474747474748 Loss: 0.14026928767411395 Corrects: 3538\n",
            "Starting epoch 17/30, LR = [0.1]\n",
            "Train step - Step 630, Loss 0.16126570105552673\n",
            "Train step - Step 640, Loss 0.13480554521083832\n",
            "Train step - Step 650, Loss 0.13438616693019867\n",
            "Train step - Step 660, Loss 0.1288232058286667\n",
            "Train epoch - Accuracy: 0.7343434343434343 Loss: 0.13401319943895243 Corrects: 3635\n",
            "Starting epoch 18/30, LR = [0.1]\n",
            "Train step - Step 670, Loss 0.12401916086673737\n",
            "Train step - Step 680, Loss 0.13236752152442932\n",
            "Train step - Step 690, Loss 0.11139464378356934\n",
            "Train step - Step 700, Loss 0.13156206905841827\n",
            "Train epoch - Accuracy: 0.7468686868686869 Loss: 0.12680385841263664 Corrects: 3697\n",
            "Starting epoch 19/30, LR = [0.1]\n",
            "Train step - Step 710, Loss 0.12778285145759583\n",
            "Train step - Step 720, Loss 0.13183175027370453\n",
            "Train step - Step 730, Loss 0.11717980355024338\n",
            "Train step - Step 740, Loss 0.11947660893201828\n",
            "Train epoch - Accuracy: 0.74989898989899 Loss: 0.12529351633305502 Corrects: 3712\n",
            "Starting epoch 20/30, LR = [0.1]\n",
            "Train step - Step 750, Loss 0.13181930780410767\n",
            "Train step - Step 760, Loss 0.12182123959064484\n",
            "Train step - Step 770, Loss 0.10000067204236984\n",
            "Train epoch - Accuracy: 0.7703030303030303 Loss: 0.1194378652717128 Corrects: 3813\n",
            "Starting epoch 21/30, LR = [0.1]\n",
            "Train step - Step 780, Loss 0.10891199111938477\n",
            "Train step - Step 790, Loss 0.12035369873046875\n",
            "Train step - Step 800, Loss 0.12671764194965363\n",
            "Train step - Step 810, Loss 0.10789351910352707\n",
            "Train epoch - Accuracy: 0.7711111111111111 Loss: 0.11603234296495264 Corrects: 3817\n",
            "Starting epoch 22/30, LR = [0.1]\n",
            "Train step - Step 820, Loss 0.11228467524051666\n",
            "Train step - Step 830, Loss 0.1011119857430458\n",
            "Train step - Step 840, Loss 0.11133885383605957\n",
            "Train step - Step 850, Loss 0.12978418171405792\n",
            "Train epoch - Accuracy: 0.7884848484848485 Loss: 0.10941039804256324 Corrects: 3903\n",
            "Starting epoch 23/30, LR = [0.1]\n",
            "Train step - Step 860, Loss 0.1109083890914917\n",
            "Train step - Step 870, Loss 0.13338612020015717\n",
            "Train step - Step 880, Loss 0.09307193011045456\n",
            "Train step - Step 890, Loss 0.11102607101202011\n",
            "Train epoch - Accuracy: 0.786060606060606 Loss: 0.10920525673663978 Corrects: 3891\n",
            "Starting epoch 24/30, LR = [0.1]\n",
            "Train step - Step 900, Loss 0.09299331158399582\n",
            "Train step - Step 910, Loss 0.10539114475250244\n",
            "Train step - Step 920, Loss 0.11014170944690704\n",
            "Train step - Step 930, Loss 0.13289809226989746\n",
            "Train epoch - Accuracy: 0.7951515151515152 Loss: 0.10569979406968512 Corrects: 3936\n",
            "Starting epoch 25/30, LR = [0.1]\n",
            "Train step - Step 940, Loss 0.11782070249319077\n",
            "Train step - Step 950, Loss 0.09757852554321289\n",
            "Train step - Step 960, Loss 0.09324585646390915\n",
            "Train step - Step 970, Loss 0.11772850900888443\n",
            "Train epoch - Accuracy: 0.8076767676767677 Loss: 0.10254787119350048 Corrects: 3998\n",
            "Starting epoch 26/30, LR = [0.1]\n",
            "Train step - Step 980, Loss 0.10313396900892258\n",
            "Train step - Step 990, Loss 0.09907063841819763\n",
            "Train step - Step 1000, Loss 0.10064178705215454\n",
            "Train step - Step 1010, Loss 0.09372573345899582\n",
            "Train epoch - Accuracy: 0.8183838383838384 Loss: 0.09665636291106541 Corrects: 4051\n",
            "Starting epoch 27/30, LR = [0.1]\n",
            "Train step - Step 1020, Loss 0.07958786189556122\n",
            "Train step - Step 1030, Loss 0.11000924557447433\n",
            "Train step - Step 1040, Loss 0.10082322359085083\n",
            "Train step - Step 1050, Loss 0.10711153596639633\n",
            "Train epoch - Accuracy: 0.813939393939394 Loss: 0.09645214479077946 Corrects: 4029\n",
            "Starting epoch 28/30, LR = [0.1]\n",
            "Train step - Step 1060, Loss 0.1129084974527359\n",
            "Train step - Step 1070, Loss 0.09202370792627335\n",
            "Train step - Step 1080, Loss 0.08230319619178772\n",
            "Train step - Step 1090, Loss 0.09590672701597214\n",
            "Train epoch - Accuracy: 0.8185858585858586 Loss: 0.09269375777003741 Corrects: 4052\n",
            "Starting epoch 29/30, LR = [0.1]\n",
            "Train step - Step 1100, Loss 0.10184990614652634\n",
            "Train step - Step 1110, Loss 0.11209221184253693\n",
            "Train step - Step 1120, Loss 0.08547361940145493\n",
            "Train step - Step 1130, Loss 0.09655109792947769\n",
            "Train epoch - Accuracy: 0.8272727272727273 Loss: 0.09338578524914655 Corrects: 4095\n",
            "Starting epoch 30/30, LR = [0.1]\n",
            "Train step - Step 1140, Loss 0.09780462831258774\n",
            "Train step - Step 1150, Loss 0.07736440747976303\n",
            "Train step - Step 1160, Loss 0.10112632811069489\n",
            "Train epoch - Accuracy: 0.8292929292929293 Loss: 0.08921827764222116 Corrects: 4105\n",
            "Training finished in 74.12229681015015 seconds\n",
            "EVALUATION:  0.76 0.1212506890296936\n",
            "TEST GROUP:  0.774\n",
            "TEST ALL:  0.774\n",
            "GROUP:  2\n",
            "Starting epoch 1/30, LR = [0.1]\n",
            "Train step - Step 0, Loss 0.3914462625980377\n",
            "Train step - Step 10, Loss 0.16814908385276794\n",
            "Train step - Step 20, Loss 0.14053140580654144\n",
            "Train step - Step 30, Loss 0.11773946136236191\n",
            "Train epoch - Accuracy: 0.35474747474747476 Loss: 0.16234275122784605 Corrects: 1756\n",
            "Starting epoch 2/30, LR = [0.1]\n",
            "Train step - Step 40, Loss 0.10683073848485947\n",
            "Train step - Step 50, Loss 0.09398075193166733\n",
            "Train step - Step 60, Loss 0.09084916114807129\n",
            "Train step - Step 70, Loss 0.0776781216263771\n",
            "Train epoch - Accuracy: 0.6139393939393939 Loss: 0.09383259934006315 Corrects: 3039\n",
            "Starting epoch 3/30, LR = [0.1]\n",
            "Train step - Step 80, Loss 0.07709549367427826\n",
            "Train step - Step 90, Loss 0.07864119857549667\n",
            "Train step - Step 100, Loss 0.07404610514640808\n",
            "Train step - Step 110, Loss 0.08185525983572006\n",
            "Train epoch - Accuracy: 0.6745454545454546 Loss: 0.07981677582769683 Corrects: 3339\n",
            "Starting epoch 4/30, LR = [0.1]\n",
            "Train step - Step 120, Loss 0.06490481644868851\n",
            "Train step - Step 130, Loss 0.08045259118080139\n",
            "Train step - Step 140, Loss 0.07326371222734451\n",
            "Train step - Step 150, Loss 0.06298907101154327\n",
            "Train epoch - Accuracy: 0.7137373737373738 Loss: 0.07255354959555346 Corrects: 3533\n",
            "Starting epoch 5/30, LR = [0.1]\n",
            "Train step - Step 160, Loss 0.07563558965921402\n",
            "Train step - Step 170, Loss 0.0658651664853096\n",
            "Train step - Step 180, Loss 0.0702485665678978\n",
            "Train step - Step 190, Loss 0.06791669130325317\n",
            "Train epoch - Accuracy: 0.7226262626262626 Loss: 0.06861314401482091 Corrects: 3577\n",
            "Starting epoch 6/30, LR = [0.1]\n",
            "Train step - Step 200, Loss 0.07431409507989883\n",
            "Train step - Step 210, Loss 0.06976519525051117\n",
            "Train step - Step 220, Loss 0.07186494022607803\n",
            "Train step - Step 230, Loss 0.06612949818372726\n",
            "Train epoch - Accuracy: 0.7468686868686869 Loss: 0.06408519385438977 Corrects: 3697\n",
            "Starting epoch 7/30, LR = [0.1]\n",
            "Train step - Step 240, Loss 0.061715662479400635\n",
            "Train step - Step 250, Loss 0.062468986958265305\n",
            "Train step - Step 260, Loss 0.06205284595489502\n",
            "Train step - Step 270, Loss 0.05774436518549919\n",
            "Train epoch - Accuracy: 0.758989898989899 Loss: 0.06122679402731886 Corrects: 3757\n",
            "Starting epoch 8/30, LR = [0.1]\n",
            "Train step - Step 280, Loss 0.06358430534601212\n",
            "Train step - Step 290, Loss 0.05865948274731636\n",
            "Train step - Step 300, Loss 0.05948994308710098\n",
            "Train step - Step 310, Loss 0.060304392129182816\n",
            "Train epoch - Accuracy: 0.7686868686868686 Loss: 0.05915982644365291 Corrects: 3805\n",
            "Starting epoch 9/30, LR = [0.1]\n",
            "Train step - Step 320, Loss 0.054667890071868896\n",
            "Train step - Step 330, Loss 0.05763961002230644\n",
            "Train step - Step 340, Loss 0.057831842452287674\n",
            "Train step - Step 350, Loss 0.04780938848853111\n",
            "Train epoch - Accuracy: 0.7747474747474747 Loss: 0.05633918017600522 Corrects: 3835\n",
            "Starting epoch 10/30, LR = [0.1]\n",
            "Train step - Step 360, Loss 0.05179555341601372\n",
            "Train step - Step 370, Loss 0.05240660533308983\n",
            "Train step - Step 380, Loss 0.05036243423819542\n",
            "Train epoch - Accuracy: 0.788080808080808 Loss: 0.05450378337592789 Corrects: 3901\n",
            "Starting epoch 11/30, LR = [0.1]\n",
            "Train step - Step 390, Loss 0.0522160641849041\n",
            "Train step - Step 400, Loss 0.06076280027627945\n",
            "Train step - Step 410, Loss 0.057587455958127975\n",
            "Train step - Step 420, Loss 0.0559830367565155\n",
            "Train epoch - Accuracy: 0.7955555555555556 Loss: 0.052162023010579026 Corrects: 3938\n",
            "Starting epoch 12/30, LR = [0.1]\n",
            "Train step - Step 430, Loss 0.0580826997756958\n",
            "Train step - Step 440, Loss 0.048088256269693375\n",
            "Train step - Step 450, Loss 0.05718463659286499\n",
            "Train step - Step 460, Loss 0.055188942700624466\n",
            "Train epoch - Accuracy: 0.802020202020202 Loss: 0.04984855488845796 Corrects: 3970\n",
            "Starting epoch 13/30, LR = [0.1]\n",
            "Train step - Step 470, Loss 0.059517741203308105\n",
            "Train step - Step 480, Loss 0.03462429717183113\n",
            "Train step - Step 490, Loss 0.048502061516046524\n",
            "Train step - Step 500, Loss 0.044571999460458755\n",
            "Train epoch - Accuracy: 0.8165656565656566 Loss: 0.04811647321389179 Corrects: 4042\n",
            "Starting epoch 14/30, LR = [0.1]\n",
            "Train step - Step 510, Loss 0.05001803860068321\n",
            "Train step - Step 520, Loss 0.04510093107819557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BCQoMhtWDJH"
      },
      "source": [
        "**Results fine tuning (catastrophic learning)**<br>\n",
        "What we expect is a dramatic drop in the perfomances with repsect to the Joint Training and the incapacity to learn new things without forgetting the old ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_4xLfwcpDz"
      },
      "source": [
        "method = \"finetuning\"\n",
        "print(\"metrics FINETUNING for seed {}\".format(RANDOM_SEED))\n",
        "\n",
        "data_plot_bar=[]\n",
        "data_plot_line=[]\n",
        "for id in range(0,10):\n",
        "    data_plot_bar.append((id+1,old_accuracies[id]))\n",
        "    data_plot_line.append(((id+1)*10,new_accuracies[id]))\n",
        "\n",
        "plt.figure(figsize=(20,7))\n",
        "accuracyDF=pd.DataFrame(data_plot_bar, columns = ['Group','Accuracy'])\n",
        "ax = sns.barplot(x=\"Group\", y=\"Accuracy\",data=accuracyDF)\n",
        "plt.title(\"Single Group Sequential Accuracy\")\n",
        "plt.show()\n",
        "\n",
        "# plot accuracy trend\n",
        "utils.plotAccuracyTrend(method, data_plot_line, RANDOM_SEED)\n",
        "\n",
        "# confusion matrix\n",
        "confusionMatrixData = confusion_matrix(all_labels_cm, all_preds_cm)\n",
        "utils.plotConfusionMatrix(method, confusionMatrixData, RANDOM_SEED)\n",
        "\n",
        "# write down json\n",
        "utils.writeMetrics(method, RANDOM_SEED, accuracies, confusionMatrixData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHBWaLNXGeI"
      },
      "source": [
        "\"\"\"num_classes_seen = 100\n",
        "dif_accuracies=printAccuracyDifference(net,old_accuracies, num_classes_seen)\n",
        "dif_accuracies\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVjGRIqDtNQP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}